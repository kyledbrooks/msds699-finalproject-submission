{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sublime-importance",
   "metadata": {},
   "source": [
    "https://deepnote.com/project/7ae94640-4599-4bbc-bd1a-6db25eca3b31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rental-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nonprofit-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm             import SVC\n",
    "\n",
    "from sklearn.decomposition   import PCA\n",
    "\n",
    "import imblearn\n",
    "from   imblearn.pipeline          import make_pipeline # scikit-learn Pipeline does not work with imblearn\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, fbeta_score, f1_score, confusion_matrix, make_scorer\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-cameroon",
   "metadata": {},
   "source": [
    "# Data Science Research Question\n",
    "-----\n",
    "## Can we develop an ML model to predict whether or not a patient will have a death event based on common heart failure predictors? Additionally, what are the most important predictors of a death event?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alike-faculty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/heart_failure_clinical_records_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-crest",
   "metadata": {},
   "source": [
    "First after very basic EDA, I summarize the features in this dataset, and how they relate to heart failure:\n",
    "- **Age** - age of patient in years\n",
    "- **Anaemia** - whether or not a patient has a decrease of red blood cells (boolean)\n",
    "- **Creatinine Phosphokinase** - level of CPK enzyme in blood in (high values may indicate muscle damage - heart is a muscle)\n",
    "- **Diabetes** - whether or not a patient has diabetes (boolean)\n",
    "- **Ejection Fraction** - percentage of blood being pumped out of left ventricle (lower values may indicate issues)\n",
    "- **High Blood Pressure** - whether or not a patient has hypertension (boolean)\n",
    "- **Platelets** - concentration of platelets in blood in kiloplatelets/mL\n",
    "- **Serum Creatinine** - concentration of creatinine in blood in mg/dL (increased levels are a marker of poor cardiac output).\n",
    "- **Serum Sodium** - level of sodium in blood in mEq/L (low concentration is a biological marker for heart failure)\n",
    "- **Sex** - whether the patient is male or female (binary: 1=Male, 0=Female)\n",
    "- **Smoking** - if the patient smokes (boolean)\n",
    "- **Time** - the follow up period for the patient up to the death event (whether they died or were censored).\n",
    "- **Death Event** - (target), whether or not the patient died during the follow up (boolean)\n",
    "    - 1 - patient died\n",
    "    - 0 - patient was censored (scientist lost contact with patient) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-fault",
   "metadata": {},
   "source": [
    "Since the time variable is populated when the scientists either lost contact with the patient, or the patient died, it is indicative of survival, and obviously not known beforehand. In other words, if we were to deploy a working model with all the columns and someone wanted to predict whether a certain patient was likely to have a death event, they would have no \"time\" variable to put as an input (since that is recorded when the patient dies). Therefore, I made the decision initially to drop time as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mounted-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.DEATH_EVENT # Our target variable is DEATH_EVENT \n",
    "X = data.drop(columns=['DEATH_EVENT', 'time'])  # Remove the target variable and time from X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "congressional-engine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many observations do we have?\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-darkness",
   "metadata": {},
   "source": [
    "After importing the data, the next step is to pull off a segment of the data that will be our testing set. This test set will be be hidden away from the models we are designing until we are ready to test a final one. Additionally, since there are only have 299 observations, I am going to split the data by a slightly higher percentage (25% as opposed to 20%) to ensure that the testing set is representative of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "critical-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing split that we are going to hide away from our model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-juvenile",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-glucose",
   "metadata": {},
   "source": [
    "After performing more extensive EDA (in a different notebook), I noticed that all of the columns were numeric types, but some represented categorical variables (i.e. whether or not someone smokes, has high blood pressure, etc.). In the dataset, these columns are already one-hot-encoded with binary 1's or 0's to indicate whether someone exhibits that characteristic. Therefore, in my feature engineering one-hot-encoding is not needed. Additionally, there are no Nan values in the training data, however I still impute for missing values, as they might be included in the testing set or data we want to use the model on.\n",
    "\n",
    "For my feature engineering, the steps I took were:\n",
    "1. Identify categorical and numerical columns and establish pipelines for each\n",
    "\n",
    "\n",
    "2. Scale the data\n",
    "    - For my numeric data I chose to use `StandardScaler()` in the pipeline, which normalizes columns to a normal distribution. This is important as many algorithms may perform poorly if individual features are not standardized. Additionally, standardization improves efficiency of many of these algorithms.\n",
    "    - It doesn't make sense to use a scaler on my categorical columns since they're simply one-hot-encoded as 1s or 0s.\n",
    "\n",
    "\n",
    "3. Impute missing values with `SimpleImputer()`\n",
    "    - For numerical columns I used the strategy *median* whereas for categorical I used *most_frequent*. These methods fill any missing values with the corresponding strategy applied to the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "catholic-friendly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       299 non-null    float64\n",
      " 1   anaemia                   299 non-null    int64  \n",
      " 2   creatinine_phosphokinase  299 non-null    int64  \n",
      " 3   diabetes                  299 non-null    int64  \n",
      " 4   ejection_fraction         299 non-null    int64  \n",
      " 5   high_blood_pressure       299 non-null    int64  \n",
      " 6   platelets                 299 non-null    float64\n",
      " 7   serum_creatinine          299 non-null    float64\n",
      " 8   serum_sodium              299 non-null    int64  \n",
      " 9   sex                       299 non-null    int64  \n",
      " 10  smoking                   299 non-null    int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 25.8 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()  # Datatypes in all columns are either integer or float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coated-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']  # These are all binary\n",
    "con_cols = ['creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "individual-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_pipe = Pipeline([('scaler', StandardScaler()),  # Standard scaler for numerical variables\n",
    "                     ('imputer', SimpleImputer(strategy='median', add_indicator=True))])\n",
    "\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent'))])  # Shouldn't standardize binary variables\n",
    "\n",
    "\n",
    "\n",
    "# Apply numerical and categorical pipeline to pre-processing step\n",
    "preprocessing = ColumnTransformer([('categorical', cat_pipe, cat_cols), \n",
    "                                   ('continuous', con_pipe, con_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-guest",
   "metadata": {},
   "source": [
    "Additionally, when looking at the target variable Death_event, I saw evidence of slight imbalanced data as the percentage of death events in the target variable was around 32%. Therefore, I will make sure to use metrics that weigh the classes so as to deal with this imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tamil-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([203,  96]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-terror",
   "metadata": {},
   "source": [
    "# Algorithms & Search\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-lodging",
   "metadata": {},
   "source": [
    "To analyze which algorithm has the best performance I utilize automated algorithm and hyperparameter search. For the search, it is important that I gear my metric towards the particular business problem. \n",
    "\n",
    "In the case of predicting whether or not a patient is going to have a death event, I want to put an emphasis on recall, as we want to reduce the amount of false negatives (instances when our model doesn't predict death event and the patient dies). We are less concerned about recall (of patients *predicted* to die, how many did we get right?) When dealing with human lives it is better to be \"safe than sorry\", so we aren't concerned with our \"success rate\" when it comes to predicting death events. Its better if our model is conservative and tries to predict as many death events as it can (even if that means a few false positives). Therefore, I chose to use the `fbeta_score` metric, as it allows us to tweak the emphasis between precision and recall. Additionally, due to the slight imbalance between classes, I choose a *weighted* fbeta_score to help alleviate this issue.\n",
    "\n",
    "When picking algorithms, I focused on three that are geared towards binary classification. I also provide details on the important parameters that will be tuned for each model via `RandomizedSearchCV()`. \n",
    "\n",
    "The three algorithms I chose to compare were:\n",
    "\n",
    "1. `LogisticRegression()` - I chose this model because it is a linear model for *classification*, which is the scope of my research question in this case.\n",
    "    - Important parameters:\n",
    "     - `penalty` - Specifies the normalization used in the penalty term\n",
    "     \n",
    "     - `C` - Inverse of regularization strength was varied (smaller values result in stronger regularization)\n",
    "     \n",
    "     - `solver` - Algorithm that is used in the optimization problem \n",
    "     \n",
    "     - `class_weight` - The weights associated with specific classes (if we have evidence of imbalanced data, setting to `balanced` may be helpful\n",
    "     \n",
    "     \n",
    "     \n",
    "2. `RandomForestClassifier()` - I chose this model because fitting a number of decision tree classifiers on various sub-samples of the data will improve accuracy in predictions and reduce overfitting \n",
    "    - Important parameters:\n",
    "        - `n_estimators` - number of trees in the forest, important because adding more trees trained on different subsets of the data reduces variance\n",
    "        - `criterion` - function used to determined the effectiveness of a split\n",
    "        - `bootstrap` - whether or not to use bootstrap samples\n",
    "            - **bootstrapping** is introducing amnesia by training trees on only a portion of the data, weakens the trees to improve *generality*\n",
    "        - `min_samples_leaf` - the minimum amount of samples required to be in a leaf node, decreasing this can decrease the validation error\n",
    "        - `class_weight` - weights assigned to classes (if None, classes are assumed to have a weight of 1)\n",
    "            - **balanced** - uses values of y to adjust weights inversely to class frequencies\n",
    "            - **balanced_subsample** - same as above, but weights are computed based on the bootstrap sample for every tree\n",
    "\n",
    "\n",
    "\n",
    "3. `KNeighborsClassifier()` - I chose this model because it was one we learned about in 621, and I thought it would be interesting to see this models performance. We learned in 621 that KNeighbors is less often used in practice, but can still be effective nonetheless, and I was interested to see if it could outperform the other algorithms selected.\n",
    "    - Important parameters:\n",
    "        - `leaf_size` - Can affect speed and the optimal value will depend on the nature of the dataset (therefore I am going to test a decent range)\n",
    "        - `n_neighbors` - Number of neighbors to use, can be unstable for the lowest values of n (i.e. 1) so start at \n",
    "        - `weights` - function to use for prediction\n",
    "            - **uniform** - all points in neighborhood weighted equally\n",
    "            - **distance** - weight points by inverse of distance (closer neighbors have greater influence)\n",
    "        - `p` - power parameter for Minkowski (1=manhattan_distance, 2=euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "impressed-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftwo_scorer = make_scorer(fbeta_score, beta=2, average='weighted')  # Score to use in RandomizedSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beginning-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyEstimator(BaseEstimator):\n",
    "    \"Pass through class, methods are present but do nothing.\"\n",
    "    def fit(self): pass\n",
    "    def score(self): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-relation",
   "metadata": {},
   "source": [
    "For the comments on importance of hyperparameters see markdown cell under Algorithms and Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "diverse-desktop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7804438448530766,\n",
       " {'clf__n_estimators': 127,\n",
       "  'clf__min_samples_leaf': 4,\n",
       "  'clf__criterion': 'entropy',\n",
       "  'clf__class_weight': 'balanced',\n",
       "  'clf__bootstrap': False,\n",
       "  'clf': RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
       "                         criterion='entropy', min_samples_leaf=4,\n",
       "                         n_estimators=127, n_jobs=-1)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps = [('preprocessing', preprocessing),\n",
    "                         ('clf', DummyEstimator())])\n",
    "\n",
    "\n",
    "search_space = [\n",
    "        {'clf': [LogisticRegression(n_jobs=-1)],\n",
    "            'clf__C': np.linspace(0.01, 5, 10),\n",
    "            'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            'clf__class_weight': ['balanced', None],\n",
    "            'clf__penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
    "                  \n",
    "                  \n",
    "        {'clf': [RandomForestClassifier(n_jobs=-1)],\n",
    "            'clf__criterion': ['gini', 'entropy'],\n",
    "            'clf__min_samples_leaf': np.linspace(1, 10, 6, dtype=int),\n",
    "            'clf__bootstrap': [True, False],\n",
    "            'clf__class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "            'clf__n_estimators': np.linspace(0, 200, 100, dtype=int)},\n",
    "    \n",
    "        {'clf': [KNeighborsClassifier(n_jobs=-1)],\n",
    "            'clf__leaf_size': np.linspace(0, 50, 10, dtype=int),\n",
    "            'clf__n_neighbors': np.linspace(2, 13, 6, dtype=int),\n",
    "            'clf__weights': ['uniform', 'distance'],\n",
    "            'clf__p': [1,2]}]\n",
    "\n",
    "    \n",
    "\n",
    "gs = RandomizedSearchCV(pipe, \n",
    "                    search_space, \n",
    "                    scoring= ftwo_scorer,  # Used to combat slight class imbalance, and gear towards recall\n",
    "                    n_iter=30,\n",
    "                    cv=5,\n",
    "                    n_jobs=-1\n",
    "                    )\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_model = gs.best_params_['clf']\n",
    "\n",
    "gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-apollo",
   "metadata": {},
   "source": [
    "As one can see the best model based on the cross validation and randomized search across algorithms and their hyperparameters is a RandomForestClassifier. To see the ideal parameters of the other models, one could comment out the other algorithms in the search_space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-crossing",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-diagnosis",
   "metadata": {},
   "source": [
    "Now that I have my ideal model based on automated hyperparameter search and model selection, next I look at a variety of evaluation metrics on the testing data to assess our models performance on the testing set. The first metric I looked at was the weighted fbeta_score, since that is the metric I used to train my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "contemporary-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [('preprocessing', preprocessing), \n",
    "                         ('clf', best_model)])\n",
    "\n",
    "fitted_model = pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "knowing-person",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7340690859209377"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred, beta=2, average='weighted') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-pollution",
   "metadata": {},
   "source": [
    "Another metric I chose to look at was balanced_accuracy_score, which gives the average of recall obtained in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "entitled-curtis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7146781789638932"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-sauce",
   "metadata": {},
   "source": [
    "Next I look at the confusion matrix, to give us an idea of precision and recall for each class in our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opponent-transportation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38, 11],\n",
       "       [ 9, 17]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEWCAYAAADl+xvlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAa20lEQVR4nO3deZwV5Z3v8c+3u1kFRAUNQQnEnRBFL4PbDaJZxEnmpeaqiRo1xlzivsWJSW4mLjF39GaMMROXYDQixjVG44LbGB0lGhUUESRRr8q4oAi4gbggv/mjqvXQ6T7nVHNOn6rD951XvTynqvqpX6N88zxVT1UpIjAzK7KWRhdgZramHGRmVngOMjMrPAeZmRWeg8zMCs9BZmaF5yBrMpL6SbpZ0puSrluDdg6SdGcta2sESbdJOrTRdVh9OcgaRNKBkmZKWiZpYfoX7n/WoOl9gY2ADSJiv+42EhG/i4gv1aCe1UiaKCkk3dBh/bbp+nurbOc0SVdU2i8i9oyIqd0s1wrCQdYAkk4CfgH8X5LQGQFcAOxVg+Y/BTwVEStr0Fa9vAbsJGmDknWHAk/V6gBK+L/vtUVEeOnBBVgXWAbsV2afPiRB93K6/ALok26bCLwIfBdYBCwEDku3nQ68D3yQHuNw4DTgipK2RwIBtKXfvwk8C7wNPAccVLJ+RsnP7Qw8AryZ/nPnkm33Aj8B/py2cycwpIvfrb3+i4Cj03WtwEvAj4F7S/Y9D3gBeAuYBXwuXT+pw+/5eEkdP03rWAFslq77drr9QuD6kvbPBu4G1Oj/Lrys2eL/x+p5OwF9gRvK7PN/gB2BscC2wHjgRyXbP0ESiMNJwup8SetFxKkkvbxrImJARFxSrhBJ6wC/BPaMiIEkYTW7k/3WB25N990A+Dlwa4ce1YHAYcCGQG/g5HLHBi4HDkk/7wHMJQntUo+Q/BmsD1wJXCepb0Tc3uH33LbkZw4GJgMDgQUd2vsu8FlJ35T0OZI/u0MjTTUrLgdZz9sAWBzlh34HAWdExKKIeI2kp3VwyfYP0u0fRMR0kl7Jlt2sZxUwRlK/iFgYEfM62efLwNMRMS0iVkbEVcBfgX8q2ee3EfFURKwAriUJoC5FxAPA+pK2JAm0yzvZ54qIWJIe8xySnmql3/OyiJiX/swHHdp7h+TP8efAFcCxEfFihfasABxkPW8JMERSW5l9PsnqvYkF6bqP2ugQhO8AA7IWEhHLga8BRwALJd0qaasq6mmvaXjJ91e6Uc804BhgNzrpoUo6WdL89ArsGyS90CEV2nyh3MaIeIhkKC2SwLUm4CDreQ8C7wF7l9nnZZKT9u1G8PfDrmotB/qXfP9E6caIuCMivggMI+llXVxFPe01vdTNmtpNA44Cpqe9pY+kQ7/vAfsD60XEYJLzc2ovvYs2yw4TJR1N0rN7OW3fmoCDrIdFxJskJ7XPl7S3pP6SeknaU9L/S3e7CviRpKGShqT7V5xq0IXZwARJIyStC/ygfYOkjSTtlZ4re49kiLqqkzamA1ukU0baJH0NGA3c0s2aAIiI54BdSc4JdjQQWElyhbNN0o+BQSXbXwVGZrkyKWkL4EzgGyRDzO9JGtu96i1PHGQNkJ7vOYnkBP5rJMOhY4Ab013OBGYCc4AngEfTdd051l3ANWlbs1g9fFrSOl4GlpKEypGdtLEE+ArJyfIlJD2Zr0TE4u7U1KHtGRHRWW/zDuB2kikZC4B3WX3Y2D7Zd4mkRysdJx3KXwGcHRGPR8TTwA+BaZL6rMnvYI0nX7Axs6Jzj8zMCs9BZmaF5yAzs8JzkJlZ4ZWblNnj1NYv1Htgo8uwDLbZapNGl2AZvLBgAUuWLFblPbvWOuhTEStXVLVvrHjtjoiYtCbHq0a+gqz3QPpsuX+jy7AM7vzPcxtdgmXwpV13XOM2YuWKqv+evjv7/Ep3YtREroLMzIpAkLMnJDnIzCwbAS2tja5iNQ4yM8tOa3SareYcZGaWkYeWZtYM3CMzs0IT7pGZWdHJPTIzawK+amlmxeaT/WZWdMJDSzNrAu6RmVmxeWhpZkUnoNUn+82s6HyOzMyKzUNLM2sG7pGZWeG5R2ZmhSbfomRmzaAGtyhJ6gvcB/QhyaLfR8Spki4jeev9m+mu34yI2eXacpCZWUY1O9n/HrB7RCyT1AuYIem2dNs/R8Tvq23IQWZm2dVgaBkRASxLv/ZKl+hOW/k6Y2dm+df+PLJqFhgiaWbJMnm1pqRWSbOBRcBdEfFQuumnkuZIOldSn0oluUdmZhllGloujohxXW2MiA+BsZIGAzdIGgP8AHgF6A1MAU4Bzih3EPfIzCy7ltbqlipFxBvAPcCkiFgYifeA3wLjK5bT3d/DzNZi7VMwKi1lm9DQtCeGpH7AF4G/ShqWrhOwNzC3UjkeWppZNqrZVcthwFRJrSSdqmsj4hZJf5I0lORs3GzgiEoNOcjMLLvaXLWcA2zXyfrds7blIDOzzOSZ/WZWZMmTrh1kZlZkEmpxkJlZwblHZmaF5yAzs8JzkJlZsSldcsRBZmaZCLlHZmbF19KSr7sbHWRmlpl7ZGZWbD5HZmbNwD0yMys0n+w3s6bgW5TMrNjkoaWZNQEHmZkVnoPMzArNJ/vNrDnkK8ccZGaWkXyLkpk1AQ8tzaz48pVjDrJa6tO7jVunnECfXm20trVy092PcdaU6Uz4hy0447h9aGkRy995j6NOn8ZzLy5udLkGnHzWVfzpgSfZYL0B3DX1FABuvWc25/72dp5ZsIibfn0C22w1osFV5k/eemR1HehKmiTpb5KekfT9eh4rD957fyV7HflLPnfQWUw48F/5/E6jGTdmJOec8nUm/8tlTDjoLH5/x0xOPnxSo0u11H6TxjP1Z5NXW7fFqGH8+sxvscO2n25QVfkmqeqlp9StR5a+Pfh8ktegvwg8IummiHiyXsfMg+Ur3gegV1srvdpaiQiCYOA6fQEYNKAfr7z2ZiNLtBI7jN2UFxYuXW3d5iM3alA1xZG3Hlk9h5bjgWci4lkASVcDewFNHWQtLeLeaacwauOhXHLdfcyat4Djz7ySa39xFCvee5+3l7/Ll751TqPLNFsjebvXsp5Dy+HACyXfX0zXrUbSZEkzJc2MlSvqWE7PWLUqmHDQWXzmyz9i+898iq03HcaRB+7G/idcwJiv/AtX3vwXzjzhq40u02yN5G1o2fDJIBExJSLGRcQ4tfVrdDk189ayFdw/6ym+sNNoxmw+nFnzFgBww12PMn6bUQ2uzmwNaO0KspeATUq+b5yua1obDB7AoAFJGPft04vdxm/FU8+/yqAB/dh0xIYATNwhWWdWVAKk6pay7Uh9JT0s6XFJ8ySdnq4fJemh9CLhNZJ6V6qpnufIHgE2lzSKJMC+DhxYx+M13CeGDOKC0w6mtaWFlhZxw388yh0z5nL8T6/k8rO/zapVq3jj7RUc85MrGl2qpY49/XIefOwZXn9zOTv8r9M48bBJDB7Un1PP+wNL31jGYadczOjNhjPtnCMaXWqO1Ky39R6we0Qsk9QLmCHpNuAk4NyIuFrSRcDhwIXlGqpbkEXESknHAHcArcClETGvXsfLg3nPvMyu3zj779bfeu8cbr13TgMqskr+/dRDOl0/acI2PVxJsbTU4GR/RASwLP3aK10C2J2POz1TgdNoVJABRMR0YHo9j2FmPayKYWOJIZJmlnyfEhFTPmoqmaY1C9iMZLrW/wfeiIiV6S6dXiTsyDP7zSwTkalHtjgixnW1MSI+BMZKGgzcAGzVnZocZGaWWa0vSEbEG5LuAXYCBktqS3tlVV0kbPj0CzMrnlpMv5A0NO2JIakfyV1A84F7gH3T3Q4F/lipHvfIzCybbOfIyhkGTE3Pk7UA10bELZKeBK6WdCbwGHBJpYYcZGaWiVBNHqwYEXOA7TpZ/yzJLY5Vc5CZWWY5u2fcQWZm2a1NT78ws2ZUu3NkNeMgM7NMknst85VkDjIzyyxnOeYgM7PsanGvZS05yMwsG3loaWYF1/48sjxxkJlZRj379NdqOMjMLLOc5ZiDzMwykk/2m1nBeR6ZmTUFB5mZFV7OcsxBZmbZuUdmZsXmm8bNrOiSByvmK8kcZGaWWUvOumQOMjPLLGc55iAzs2zkm8bNrBnk7BRZ10Em6d+B6Gp7RBxXl4rMLPeKdLJ/Zo9VYWaFIZIrl3nSZZBFxNTS75L6R8Q79S/JzPIuZx0yKr5lU9JO6Zt//5p+31bSBXWvzMzyScnzyKpZeko1rwv+BbAHsAQgIh4HJtSxJjPLOam6padUddUyIl7okK4f1qccM8s7UcwJsS9I2hkISb2A44H59S3LzPIsb1ctqxlaHgEcDQwHXgbGpt/NbC1U7bAyV0PLiFgMHNQDtZhZQdRiaClpE+ByYCOSOatTIuI8SacB/xt4Ld31hxExvVxbFYNM0qeB84Ad04M9CJwYEc92+zcws0KrUWdrJfDdiHhU0kBglqS70m3nRsS/VdtQNUPLK4FrgWHAJ4HrgKsyFmxmTaQW0y8iYmFEPJp+fpvk3Pvw7tRTTZD1j4hpEbEyXa4A+nbnYGZWfMlVy+oWYIikmSXL5E7blEYC2wEPpauOkTRH0qWS1qtUU7l7LddPP94m6fvA1SRDy68BZcerZtbElOnBiosjYlz55jQAuB44ISLeknQh8BOSvPkJcA7wrXJtlDtHNittqL3i75RsC+AHZcs3s6ZVq1n76ZSu64HfRcQfACLi1ZLtFwO3VGqn3L2Wo2pQp5k1mfah5Rq3k6ThJcD8iPh5yfphEbEw/boPMLdSW1XN7Jc0BhhNybmxiLg8S9Fm1jxq1CPbBTgYeELS7HTdD4EDJI0lGfk9z+qjwU5VM/3iVGAiSZBNB/YEZpDM/zCztVAtYiwiZnTRVOZz8NVctdwX+DzwSkQcBmwLrJv1QGbWHCRobVFVS0+pZmi5IiJWSVopaRCwCNikznWZWY4V8Zn9MyUNBi4muZK5jGR2v5mtpXKWY1Xda3lU+vEiSbcDgyJiTn3LMrO8EirOY3wkbV9uW/utBWa2lunhJ1tUo1yP7Jwy2wLYvca1sN3WI/jzQ7+qdbNWRw8+s6TRJVgGK96vzTNRC3OOLCJ268lCzKwYBLQWJcjMzLqSswfEOsjMLDsHmZkVWvIY63wlWTXvtZSkb0j6cfp9hKTx9S/NzPIqw/PIeqaeKva5ANgJOCD9/jZwft0qMrPcK9zLR4AdImJ7SY8BRMTrknrXuS4zyykBbTkbWlYTZB9IaiWZO4akocCqulZlZrmWsxyrKsh+CdwAbCjppyRPw/hRXasys9ySCnSLUruI+J2kWSSP8hGwd0T4TeNma7Gc5VhVD1YcAbwD3Fy6LiL+q56FmVl+FXEe2a18/BKSvsAo4G/AZ+pYl5nllKBHH5pYjWqGlp8t/Z4+FeOoLnY3s2bXw3PEqpF5Zn/6evMd6lGMmRWDavLU/tqp5hzZSSVfW4DtgZfrVpGZ5VqtXgdXS9X0yAaWfF5Jcs7s+vqUY2ZFUKggSyfCDoyIk3uoHjMrgLzdNF7uUddtEbFS0i49WZCZ5VvyOrhGV7G6cj2yh0nOh82WdBNwHbC8fWNE/KHOtZlZThVuZj/J3LElJM/ob59PFoCDzGwtVLST/RumVyzn8nGAtYu6VmVmuZazDlnZIGsFBkCnE0YcZGZrLdFSoHlkCyPijB6rxMwKQdSmRyZpE+ByYCOSztGUiDhP0vrANcBI4Hlg/4h4vVxb5a495CtyzSwfBG0tqmqpYCXw3YgYDewIHC1pNPB94O6I2By4O/1eVrkg+3x1v5WZrU3ae2Rr+qjriFgYEY+mn98G5gPDgb2AqeluU4G9K9VU7gW9S6v5pcxs7ZNh+sUQSTNLvk+JiCkdd5I0EtgOeAjYKCIWppteIRl6luXXwZlZZhnOkS2OiHHl29IAktseT4iIt0rvGoiIkFTx4mLO5ueaWd6JJDiqWSq2JfUiCbHflUyyf1XSsHT7MGBRpXYcZGaWjZKhZTVL2WaSrtclwPyI+HnJppuAQ9PPhwJ/rFSSh5Zmlkkys78mkxp2AQ4GnpA0O133Q+As4FpJhwMLgP0rNeQgM7PMahFjETGjTFOZZk04yMwssyLdomRm1gkV53lkZmadab9qmScOMjPLrIjPIzMz+5gK9KhrM7POeGhpZk3BPTIzK7x8xZiDzMwyEtDqHpmZFV3OcsxBZmZZCeVscOkgM7PM3CMzs0JLpl/kK8kcZGaWTRXP4+9pDjIzy8y3KJlZoSUPVmx0FatzkJlZZr5qaWaFl7ORpYOsni666h6m3vgARHDI3rtw5IG7Nbok6+Dci27k4ceeYvCgdbjwZ0cD8K/nXctLC5cAsGz5uwxYpy+/OuvIRpaZO2tNj0zSpcBXgEURMaZex8mrJ595mak3PsDdU/+Z3m2t7HvcBezxuTF8epOhjS7NSnxh17H80x7jOeeCGz5a94PjP37XxcXTbmed/n0bUVpu5fEcWT2fxnEZMKmO7efaU8+/wrgxI+nftzdtba3ssv1m3HzP7EaXZR18duuRDBzQr9NtEcH9f5nHrjt/toeryrkqXwXXk1c26xZkEXEfsLRe7efd1pt+kgdnP8PSN5bxzrvvc9cD83jp1dcbXZZlMPevCxi87gCGD9ug0aXkjqpcekrDz5FJmgxMBthkxIgGV1M7W476BMcf8kW+euz59O/XmzFbbExrS94eR2fl/OcDTzBx57XurEhFNXyvZc00/G9WREyJiHERMW7okOY6f3TwXjtz77RTmD7lRAYP7M+mIzZsdElWpQ8//JAHHp7PhJ0cZJ3JW4+s4UHWzF5b+jYAL7yylFvueZz9Jo1rcEVWrceeeJaNPzmEIRus2+hS8ilnSdbwoWUzO+SU3/D6m8tpa2vlZ9/bn3UH9m90SdbB2b+8jjnzn+ett9/h4KPP4Rv7TmSP3f4H9z041yf5y8jb0LKe0y+uAiYCQyS9CJwaEZfU63h5dNvFJza6BKvglOP263T9SUfu08OVFEu+YqyOQRYRB9SrbTNrsJwlmYeWZpZJcvorX0nmk/1mlk36PLJqlopNSZdKWiRpbsm60yS9JGl2uvxjpXYcZGaWWQ0vWl5G53cAnRsRY9NleqVGPLQ0s4xUsxf0RsR9kkauaTvukZlZZhmGlkMkzSxZJld5iGMkzUmHnutV2tlBZmaZVDusTPtsi9vv3EmXKVUc4kJgU2AssBA4p9IPOMjMLLs6zuyPiFcj4sOIWAVcDIyv9DMOMjPLTFX+r1ttS8NKvu4DzO1q33Y+2W9mmdXqDqXO7gACJkoaCwTwPPCdSu04yMwsmxq+17KLO4Ay38roIDOzzPI2s99BZmaZCL9FycyaQM5yzEFmZt2QsyRzkJlZZmvNgxXNrHnlK8YcZGbWHTlLMgeZmWWSxwcrOsjMLJsaToitFQeZmWWWsxxzkJlZVrV7sGKtOMjMLLOc5ZiDzMyy6eGXiFfFQWZm2eUsyRxkZpaZp1+YWeH5HJmZFZugxUFmZsWXryRzkJlZJn6wopk1hZzlmIPMzLJzj8zMCs+3KJlZ4eUrxhxkZpaR/BgfM2sGntlvZsWXrxxzkJlZdjnLMQeZmWWl3L0OrqXRBZhZsbTP7K9mqdiWdKmkRZLmlqxbX9Jdkp5O/7lepXYcZGbWSJcBkzqs+z5wd0RsDtydfi/LQWZmmdWqRxYR9wFLO6zeC5iafp4K7F2pHZ8jM7PMMky/GCJpZsn3KRExpcLPbBQRC9PPrwAbVTqIg8zMssk2IXZxRIzr7qEiIiRFpf08tDSzTGp5sr8Lr0oaBpD+c1GlH3CQmVlmqvJ/3XQTcGj6+VDgj5V+wEFmZpnVcPrFVcCDwJaSXpR0OHAW8EVJTwNfSL+X5XNkZpZZrabDRsQBXWz6fJZ2HGRmll2+JvY7yMwsG0HublFSRMUrmz1G0mvAgkbXUQdDgMWNLsIyadZ/Z5+KiKFr0oCk20n+fKqxOCI6ztyvuVwFWbOSNHNN5tJYz/O/s2LxVUszKzwHmZkVnoOsZ1S6t8zyx//OCsTnyMys8NwjM7PCc5CZWeE5yOpI0iRJf5P0jKSKT7m0xuvs0cuWfw6yOpHUCpwP7AmMBg6QNLqxVVkVLuPvH71sOecgq5/xwDMR8WxEvA9cTfIIX8uxLh69bDnnIKuf4cALJd9fTNeZWY05yMys8Bxk9fMSsEnJ943TdWZWYw6y+nkE2FzSKEm9ga+TPMLXzGrMQVYnEbESOAa4A5gPXBsR8xpblVXSxaOXLed8i5KZFZ57ZGZWeA4yMys8B5mZFZ6DzMwKz0FmZoXnICsQSR9Kmi1prqTrJPVfg7Yuk7Rv+vk35W5olzRR0s7dOMbzkv7ubTtdre+wz7KMxzpN0slZa7Tm4CArlhURMTYixgDvA0eUbpTUrfeURsS3I+LJMrtMBDIHmVlPcZAV1/3AZmlv6X5JNwFPSmqV9DNJj0iaI+k7AEr8Kn0+2n8AG7Y3JOleSePSz5MkPSrpcUl3SxpJEpgnpr3Bz0kaKun69BiPSNol/dkNJN0paZ6k31DF+6gl3ShpVvozkztsOzddf7ekoem6TSXdnv7M/ZK2qsmfphWa3zReQGnPa0/g9nTV9sCYiHguDYM3I+IfJPUB/izpTmA7YEuSZ6NtBDwJXNqh3aHAxcCEtK31I2KppIuAZRHxb+l+VwLnRsQMSSNI7l7YGjgVmBERZ0j6MlDNrPhvpcfoBzwi6fqIWAKsA8yMiBMl/Tht+xiSl4IcERFPS9oBuADYvRt/jNZEHGTF0k/S7PTz/cAlJEO+hyPiuXT9l4Bt2s9/AesCmwMTgKsi4kPgZUl/6qT9HYH72tuKiK6ey/UFYLT0UYdrkKQB6TG+mv7srZJer+J3Ok7SPunnTdJalwCrgGvS9VcAf0iPsTNwXcmx+1RxDGtyDrJiWRERY0tXpH+hl5euAo6NiDs67PePNayjBdgxIt7tpJaqSZpIEoo7RcQ7ku4F+naxe6THfaPjn4GZz5E1nzuAIyX1ApC0haR1gPuAr6Xn0IYBu3Xys38BJkgalf7s+un6t4GBJfvdCRzb/kXS2PTjfcCB6bo9gfUq1Lou8HoaYluR9AjbtQDtvcoDSYasbwHPSdovPYYkbVvhGLYWcJA1n9+QnP96NH2Bxq9Jet43AE+n2y4necLDaiLiNWAyyTDucT4e2t0M7NN+sh84DhiXXkx4ko+vnp5OEoTzSIaY/1Wh1tuBNknzgbNIgrTdcmB8+jvsDpyRrj8IODytbx5+fLjhp1+YWRNwj8zMCs9BZmaF5yAzs8JzkJlZ4TnIzKzwHGRmVngOMjMrvP8Gltl/FXUIcScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = plot_confusion_matrix(fitted_model, X_test, y_test, cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "disp.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "inner-lawrence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79        49\n",
      "           1       0.61      0.65      0.63        26\n",
      "\n",
      "    accuracy                           0.73        75\n",
      "   macro avg       0.71      0.71      0.71        75\n",
      "weighted avg       0.74      0.73      0.74        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-privilege",
   "metadata": {},
   "source": [
    "Above is a summary of the precision and recall in the chosen model. As one can see, our model still struggles with recall for predicting death events (class 1). It seems like the model performs well at predicting whether a patient lives (class 0), but struggles with death event. For further work I would like to further investigate how to improve our models performance when it comes to class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-journal",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "----\n",
    "To answer my question of which features are the best predictors of a death event I look at feature importance and select the 3 most influential features based on my ideal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "wooden-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = SelectFromModel(best_model, max_features=3)\n",
    "\n",
    "\n",
    "fs.fit_transform(X_train, y_train)\n",
    "\n",
    "features_to_keep = fs.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "radio-beads",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'ejection_fraction', 'serum_creatinine']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x, y in zip(list(X.columns), list(features_to_keep)) if y == True]  # These are the most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-liability",
   "metadata": {},
   "source": [
    "As one can see from above, the most important features for predicting a death event are age, ejection_fraction, and serum_creatine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-tucson",
   "metadata": {},
   "source": [
    "# Results and Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-samba",
   "metadata": {},
   "source": [
    "Below are the pipeline steps for my randomized search and model selection (DummyEstimator() is a placeholder for the three models analyzed in my randomized search):\n",
    "- scaler for numerical columns\n",
    "- imputation of missing values (median for continuous and mode for categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "municipal-tribute",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('categorical',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent'))]),\n",
       "                                                  ['anaemia', 'diabetes',\n",
       "                                                   'high_blood_pressure', 'sex',\n",
       "                                                   'smoking']),\n",
       "                                                 ('continuous',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  ('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='median'))]),\n",
       "                                                  ['creatinine_phosphokinase',\n",
       "                                                   'ejection_fraction',\n",
       "                                                   'platelets',\n",
       "                                                   'serum_creatinine',\n",
       "                                                   'serum_sodium', 'age'])])),\n",
       "                ('clf', DummyEstimator())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.estimator  # RandomizedSearchCV pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-killer",
   "metadata": {},
   "source": [
    "Based on my algorithm and hyperparameter search the single best model and its non-default hyperparameters are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "brown-being",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
       "                       criterion='entropy', min_samples_leaf=4,\n",
       "                       n_estimators=127, n_jobs=-1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-desktop",
   "metadata": {},
   "source": [
    "Overall, I was somewhat successful at building a model to predict heart failure. My model is fairly accurate, however when I looked into the specific precision/recall for predicting a death event, I saw that my model struggled. Perhaps this has something to do with the class imbalance, but for future work I would like to research ways to improve this particular aspect of the models performance. \n",
    "\n",
    "Given that this model's goal is to help save lives by warning at risk patients, it would be ideal if our model had better performance. Perhaps a simpler model (reducing the number of features) would have more predictive power. For future work I might make a model including the top three most important features, and seeing how that performs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
